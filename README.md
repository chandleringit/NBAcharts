# de-project
2025 Data Engineering Course Project

## ğŸ—ï¸ å°ˆæ¡ˆæ¶æ§‹æ¦‚è¿°

æœ¬å°ˆæ¡ˆæ˜¯ä¸€å€‹å®Œæ•´çš„è³‡æ–™å·¥ç¨‹ç®¡é“ï¼Œæ•´åˆäº†å¤šå€‹ç¾ä»£åŒ–çš„è³‡æ–™è™•ç†å·¥å…·ï¼š

- **ğŸ•·ï¸ è³‡æ–™æ“·å–**: ä½¿ç”¨ Python çˆ¬èŸ²æŠ€è¡“æ“·å– Hahow ç·šä¸Šèª²ç¨‹å¹³å°è³‡æ–™
- **âš¡ ä»»å‹™èª¿åº¦**: é€é Celery + RabbitMQ å¯¦ç¾åˆ†æ•£å¼ä»»å‹™è™•ç†
- **ğŸš€ å·¥ä½œæµç¨‹ç®¡ç†**: ä½¿ç”¨ Apache Airflow é€²è¡Œ ETL æµç¨‹ç·¨æ’
- **ğŸ—„ï¸ è³‡æ–™å­˜å„²**: MySQL è³‡æ–™åº«å„²å­˜çµæ§‹åŒ–è³‡æ–™
- **ğŸ“Š è³‡æ–™è¦–è¦ºåŒ–**: Metabase å»ºç«‹å•†æ¥­æ™ºæ…§å„€è¡¨æ¿
- **ğŸ³ å®¹å™¨åŒ–éƒ¨ç½²**: Docker & Docker Compose çµ±ä¸€ç®¡ç†æœå‹™

### è³‡æ–™æµç¨‹
```
Hahow ç¶²ç«™ â†’ Python çˆ¬èŸ² â†’ RabbitMQ â†’ Celery Workers â†’ MySQL â†’ Metabase
                â†‘                                                    â†“
            Airflow DAG                                         å•†æ¥­æ™ºæ…§å ±è¡¨
```

## è³‡æ–™å¤¾çµæ§‹
```
de-project/
â”œâ”€â”€ .venv/                                   # Python è™›æ“¬ç’°å¢ƒ
â”œâ”€â”€ .gitignore                               # Git å¿½ç•¥æª”æ¡ˆè¨­å®š
â”œâ”€â”€ .python-version                          # Python ç‰ˆæœ¬æŒ‡å®š
â”œâ”€â”€ README.md                                # å°ˆæ¡ˆèªªæ˜æ–‡ä»¶
â”œâ”€â”€ pyproject.toml                           # Python å°ˆæ¡ˆé…ç½®æª”
â”œâ”€â”€ uv.lock                                  # UV å¥—ä»¶ç®¡ç†é–å®šæª”
â”œâ”€â”€ Dockerfile                               # Docker æ˜ åƒæª”é…ç½®
â”‚
â”œâ”€â”€ data_ingestion/                          # ğŸ”¥ æ ¸å¿ƒè³‡æ–™æ“·å–æ¨¡çµ„
â”‚   â”œâ”€â”€ __init__.py                          # Python å¥—ä»¶åˆå§‹åŒ–
â”‚   â”œâ”€â”€ config.py                            # é…ç½®æª”ï¼ˆç’°å¢ƒè®Šæ•¸ï¼‰
â”‚   â”œâ”€â”€ worker.py                            # Celery Worker è¨­å®š
â”‚   â”œâ”€â”€ tasks.py                             # Celery ä»»å‹™å®šç¾©
â”‚   â”œâ”€â”€ producer.py                          # åŸºæœ¬ Producer
â”‚   â”œâ”€â”€ mysql.py                             # MySQL é€£ç·šæ¨¡çµ„
â”‚   â”œâ”€â”€ crawler.py                           # çˆ¬èŸ²åŸºç¤æ¨¡çµ„
â”‚   â”‚
â”‚   â”œâ”€â”€ # Hahow çˆ¬èŸ²ç›¸é—œæ¨¡çµ„
â”‚   â”œâ”€â”€ hahow_crawler_common.py              # Hahow çˆ¬èŸ²å…±ç”¨å‡½å¼
â”‚   â”œâ”€â”€ hahow_crawler_course.py              # Hahow èª²ç¨‹çˆ¬èŸ²
â”‚   â”œâ”€â”€ hahow_crawler_course_optimized.py    # Hahow èª²ç¨‹çˆ¬èŸ²å„ªåŒ–ç‰ˆ
â”‚   â”œâ”€â”€ hahow_crawler_course_optimized_sales.py # Hahow èª²ç¨‹éŠ·å”®çˆ¬èŸ²
â”‚   â”œâ”€â”€ hahow_crawler_article.py             # Hahow æ–‡ç« çˆ¬èŸ²
â”‚   â”œâ”€â”€ hahow_crawler_article_optimized.py   # Hahow æ–‡ç« çˆ¬èŸ²å„ªåŒ–ç‰ˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ # Producer ç›¸é—œæ¨¡çµ„
â”‚   â”œâ”€â”€ producer_crawler_hahow_all.py        # Hahow å…¨éƒ¨è³‡æ–™ Producer
â”‚   â”œâ”€â”€ producer_crawler_hahow_by_queue.py   # Hahow åˆ†éšŠåˆ— Producer
â”‚   â”œâ”€â”€ producer_crawler_hahow_course.py     # Hahow èª²ç¨‹ Producer
â”‚   â”‚
â”‚   â””â”€â”€ # Tasks ç›¸é—œæ¨¡çµ„
â”‚       â”œâ”€â”€ tasks_crawler_hahow_course.py    # Hahow èª²ç¨‹çˆ¬èŸ²ä»»å‹™
â”‚       â””â”€â”€ tasks_crawler_hahow_article.py   # Hahow æ–‡ç« çˆ¬èŸ²ä»»å‹™
â”‚
â”œâ”€â”€ airflow/                                 # ğŸš€ Apache Airflow å·¥ä½œæµç¨‹ç®¡ç†
â”‚   â”œâ”€â”€ airflow.cfg                          # Airflow é…ç½®æª”
â”‚   â”œâ”€â”€ Dockerfile                           # Airflow Docker æ˜ åƒæª”
â”‚   â”œâ”€â”€ docker-compose-airflow.yml           # Airflow Docker Compose é…ç½®
â”‚   â”œâ”€â”€ logs/                                # Airflow åŸ·è¡Œæ—¥èªŒ
â”‚   â”œâ”€â”€ plugins/                             # Airflow è‡ªè¨‚å¤–æ›
â”‚   â””â”€â”€ dags/                                # Airflow DAG å·¥ä½œæµç¨‹å®šç¾©
â”‚       â”œâ”€â”€ example_first_dag.py             # åŸºç¤ç¯„ä¾‹ DAG
â”‚       â”œâ”€â”€ example_dummy_tasks_dag.py       # è™›æ“¬ä»»å‹™ç¯„ä¾‹ DAG
â”‚       â”œâ”€â”€ example_parallel_dag.py          # ä¸¦è¡Œä»»å‹™ç¯„ä¾‹ DAG
â”‚       â”œâ”€â”€ hahow_crawler_dag.py             # Hahow çˆ¬èŸ² DAG
â”‚       â””â”€â”€ hahow_crawler_producer_dag.py    # Hahow Producer DAG
â”‚
â”‚
â”œâ”€â”€ example/                                 # ğŸ“š SQL ç¯„ä¾‹èˆ‡æŸ¥è©¢
â”‚   â”œâ”€â”€ employees.sql                        # å“¡å·¥è³‡æ–™è¡¨ç¯„ä¾‹
â”‚   â”œâ”€â”€ students.sql                         # å­¸ç”Ÿè³‡æ–™è¡¨ç¯„ä¾‹
â”‚   â”œâ”€â”€ ecommerce.sql                        # é›»å•†è³‡æ–™è¡¨ç¯„ä¾‹
â”‚   â””â”€â”€ course_sales_queries.sql             # èª²ç¨‹éŠ·å”®æŸ¥è©¢ç¯„ä¾‹
â”‚
â”œâ”€â”€ output/                                  # ğŸ“ è¼¸å‡ºè³‡æ–™ç›®éŒ„
â”‚   â”œâ”€â”€ hahow_course_*.csv                   # Hahow èª²ç¨‹è³‡æ–™
â”‚   â””â”€â”€ hahow_article_*.csv                  # Hahow æ–‡ç« è³‡æ–™
â”‚
â””â”€â”€ # Docker Compose é…ç½®æª”æ¡ˆ
    â”œâ”€â”€ docker-compose-broker.yml            # RabbitMQ Broker é…ç½®
    â”œâ”€â”€ docker-compose-mysql.yml             # MySQL è³‡æ–™åº«é…ç½®
    â”œâ”€â”€ docker-compose-producer.yml          # Producer æœå‹™é…ç½®
    â””â”€â”€ docker-compose-worker.yml            # Worker æœå‹™é…ç½®
```



## æŒ‡ä»¤

### ğŸ”§ ç’°å¢ƒè¨­å®š
```bash
# å»ºç«‹è™›æ“¬ç’°å¢ƒä¸¦å®‰è£ä¾è³´ï¼ˆåŒæ­¥ï¼‰
uv sync

# å»ºç«‹ä¸€å€‹ network è®“å„æœå‹™èƒ½æºé€š
docker network create my_network
```

### ğŸŒ ç’°å¢ƒè®Šæ•¸è¨­å®š
æœ¬å°ˆæ¡ˆä½¿ç”¨ç´” Python å¯¦ç¾è‡ªå‹•è¼‰å…¥ `.env` æª”æ¡ˆä¸­çš„ç’°å¢ƒè®Šæ•¸ï¼Œç„¡éœ€é¡å¤–å¥—ä»¶ï¼Œé¡ä¼¼ pipenv çš„è¡Œç‚ºã€‚

### ğŸ”„ è¼‰å…¥ç’°å¢ƒè®Šæ•¸çš„æ–¹æ³•

**æ–¹æ³•ä¸€ï¼šä½¿ç”¨ uv å…§å»ºåŠŸèƒ½**
```bash
uv run --env-file .env data_ingestion/producer.py
uv run --env-file .env celery -A data_ingestion.worker worker --loglevel=info
```
- âœ… uv åŸç”Ÿæ”¯æ´
- âœ… æ˜ç¢ºæŒ‡å®šç’°å¢ƒè®Šæ•¸ä¾†æº
- âœ… ä¸æ±¡æŸ“ç³»çµ±ç’°å¢ƒ

**æ–¹æ³•äºŒï¼šä½¿ç”¨ source è¼‰å…¥**
```bash
source .env
uv run data_ingestion/producer.py
uv run celery -A data_ingestion.worker worker --loglevel=info
```
- âœ… æœ€ç°¡å–®çš„æ–¹å¼
- âš ï¸ æœƒå½±éŸ¿ç•¶å‰ shell ç’°å¢ƒ

**æ–¹æ³•ä¸‰ï¼šç›´æ¥åœ¨çµ‚ç«¯è¼‰å…¥**
```bash
# æ–¹å¼ 1: ä½¿ç”¨ sourceï¼ˆæœ€ç°¡å–®ï¼‰
source .env
python data_ingestion/hahow_crawler_article_optimized.py

**ç‰¹è‰²åŠŸèƒ½ï¼š**
- âœ… å½ˆæ€§é¸æ“‡ï¼šå¤šç¨®æ–¹å¼é©æ‡‰ä¸åŒéœ€æ±‚
- âœ… é è¨­å€¼ï¼šå¦‚æœ `.env` ä¸å­˜åœ¨æˆ–è®Šæ•¸æœªè¨­å®šï¼Œä½¿ç”¨ç¨‹å¼ç¢¼é è¨­å€¼  
- âœ… é–‹ç™¼å‹å–„ï¼šé¡ä¼¼ pipenv çš„ä½¿ç”¨é«”é©—

### ğŸ“Š Metabase å•†æ¥­æ™ºæ…§å„€è¡¨æ¿
```bash
# å•Ÿå‹• Metabase æœå‹™ï¼ˆåŒ…å« PostgreSQLï¼‰
docker compose -f metabase/docker-compose.yml up -d

# åœæ­¢ Metabase æœå‹™
docker compose -f metabase/docker-compose.yml down

# æŸ¥çœ‹ Metabase æœå‹™ç‹€æ…‹
docker compose -f metabase/docker-compose.yml ps

# å­˜å– Metabase ç¶²é ä»‹é¢
# http://localhost:3000
```

### ğŸš€ Apache Airflow å·¥ä½œæµç¨‹ç®¡ç†
```bash
# å•Ÿå‹• Airflow æœå‹™
docker compose -f airflow/docker-compose-airflow.yml up -d

# åœæ­¢ Airflow æœå‹™
docker compose -f airflow/docker-compose-airflow.yml down

# æŸ¥çœ‹ Airflow æœå‹™ç‹€æ…‹
docker compose -f airflow/docker-compose-airflow.yml ps

# æŸ¥çœ‹ Airflow æœå‹™æ—¥èªŒ
docker compose -f airflow/docker-compose-airflow.yml logs -f

# å­˜å– Airflow ç¶²é ä»‹é¢
# http://localhost:8080
# é è¨­å¸³è™Ÿå¯†ç : airflow / airflow
```

### ğŸ”¥ RabbitMQ Broker èˆ‡ Celery Worker
```bash
# å•Ÿå‹• RabbitMQ Broker æœå‹™
docker compose -f docker-compose-broker.yml up -d

# åœæ­¢ä¸¦ç§»é™¤ RabbitMQ æœå‹™
docker compose -f docker-compose-broker.yml down

# æŸ¥çœ‹æœå‹™ logs
docker logs -f rabbitmq
docker logs -f flower

# å­˜å– RabbitMQ ç®¡ç†ä»‹é¢: http://localhost:15672 (guest/guest)
# å­˜å– Flower ç›£æ§ä»‹é¢: http://localhost:5555
```

### ğŸ—„ï¸ MySQL è³‡æ–™åº«
```bash
# å•Ÿå‹• MySQL æœå‹™
docker compose -f docker-compose-mysql.yml up -d

# åœæ­¢ MySQL æœå‹™
docker compose -f docker-compose-mysql.yml down
```

### ğŸ•·ï¸ çˆ¬èŸ²èˆ‡ä»»å‹™åŸ·è¡Œ
```bash
# ä¸€æ¬¡è¼‰å…¥ï¼Œå¤šæ¬¡ä½¿ç”¨
source .env

# Producer ç™¼é€ä»»å‹™
uv run data_ingestion/producer.py
uv run data_ingestion/producer_crawler_hahow_all.py
uv run data_ingestion/producer_crawler_hahow_by_queue.py
uv run data_ingestion/producer_crawler_hahow_course.py

# å•Ÿå‹• Worker
uv run celery -A data_ingestion.worker worker --loglevel=info --hostname=worker1%h
uv run celery -A data_ingestion.worker worker --loglevel=info --hostname=worker2%h

# æŒ‡å®š Worker concurrency
uv run celery -A data_ingestion.worker worker --loglevel=info --hostname=worker1%h --concurrency=1
uv run celery -A data_ingestion.worker worker --loglevel=info --hostname=worker2%h --concurrency=1

# æŒ‡å®š Worker queue
uv run celery -A data_ingestion.worker worker --loglevel=info --hostname=worker1%h -Q hahow_course
uv run celery -A data_ingestion.worker worker --loglevel=info --hostname=worker2%h -Q hahow_article
uv run celery -A data_ingestion.worker worker --loglevel=info --hostname=worker3%h -Q hahow_course,hahow_article
```

### ğŸ³ Docker Compose æœå‹™ç®¡ç†
```bash
# å•Ÿå‹•æ‰€æœ‰ç›¸é—œæœå‹™
docker compose -f docker-compose-broker.yml up -d
docker compose -f docker-compose-mysql.yml up -d
docker compose -f airflow/docker-compose-airflow.yml up -d
docker compose -f metabase/docker-compose-metabase.yml up -d

# åœæ­¢æ‰€æœ‰æœå‹™
docker compose -f docker-compose-broker.yml down
docker compose -f docker-compose-mysql.yml down
docker compose -f airflow/docker-compose-airflow.yml down
docker compose -f metabase/docker-compose-metabase.yml down

# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨ç‹€æ…‹
docker ps -a
```